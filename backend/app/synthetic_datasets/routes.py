"""Synthetic Datasets API Routes."""

# ============================================================================
# IMPORTS
# ============================================================================

# Standard library
from typing import List, Optional
import uuid
import logging

logger = logging.getLogger(__name__)

# Third-party
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.responses import FileResponse
from sqlmodel import Session
from pathlib import Path

# Local - Core
from app.core.dependencies import get_db, get_current_user
from app.core.config import settings

# Local - Storage
from app.storage.s3 import (
    get_storage_service,
    S3ConfigurationError,
    S3StorageError,
)

# Local - Datasets (reuse Dataset model)
from app.datasets.models import Dataset
from app.datasets.schemas import DatasetResponse

# Local - Module
from .repositories import (
    list_synthetic_datasets,
    get_synthetic_dataset_by_id,
    delete_synthetic_dataset
)

# ============================================================================
# SETUP
# ============================================================================

router = APIRouter(prefix="/synthetic-datasets", tags=["synthetic-datasets"])

# S3 storage flag
_s3_available: Optional[bool] = None

def is_s3_available() -> bool:
    """Check if S3 storage is configured and available."""
    global _s3_available
    if _s3_available is None:
        try:
            get_storage_service()
            _s3_available = True
        except S3ConfigurationError:
            _s3_available = False
    return _s3_available

# ============================================================================
# ENDPOINTS
# ============================================================================

@router.get("/", response_model=List[DatasetResponse])
def list_synthetic(
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """
    List all synthetic datasets for the current user.
    
    Returns datasets that were generated by the user's generators.
    """
    # SECURITY: Filter to only return synthetic datasets from user's generators
    from sqlmodel import select
    from app.generators.models import Generator
    
    # Get all generators owned by current user
    generator_statement = select(Generator.output_dataset_id).where(
        Generator.created_by == current_user.id,
        Generator.output_dataset_id.isnot(None)
    )
    output_dataset_ids = db.exec(generator_statement).all()
    
    # Get datasets that match those output IDs
    if not output_dataset_ids:
        return []
    
    dataset_statement = select(Dataset).where(Dataset.id.in_(output_dataset_ids))
    synthetic_datasets = db.exec(dataset_statement).all()
    
    return synthetic_datasets


@router.get("/{dataset_id}", response_model=DatasetResponse)
def get_synthetic_dataset(
    dataset_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Get a specific synthetic dataset by ID."""
    try:
        dataset_uuid = uuid.UUID(dataset_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid UUID format")
    
    dataset = get_synthetic_dataset_by_id(db, dataset_uuid)
    if not dataset:
        raise HTTPException(status_code=404, detail="Synthetic dataset not found")
    
    return dataset


@router.get("/{dataset_id}/download")
def download_synthetic_dataset(
    dataset_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Download a synthetic dataset file. Returns presigned S3 URL or local file."""
    try:
        dataset_uuid = uuid.UUID(dataset_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid UUID format")
    
    dataset = get_synthetic_dataset_by_id(db, dataset_uuid)
    if not dataset:
        raise HTTPException(status_code=404, detail="Synthetic dataset not found")
    
    # Try S3 first if configured and dataset has s3_key
    if is_s3_available() and dataset.s3_key:
        try:
            storage = get_storage_service()
            download_url = storage.generate_download_url(
                key=dataset.s3_key,
                filename=f"{dataset.name}.csv",
                expires_in=3600
            )
            return {"download_url": download_url, "expires_in": 3600}
        except S3StorageError as e:
            logger.warning(f"S3 download failed, falling back to local: {e}")
    
    # Fallback to local file
    upload_dir = Path(settings.upload_dir)
    file_path = upload_dir / dataset.original_filename
    
    if not file_path.exists():
        raise HTTPException(
            status_code=404,
            detail=f"File not found: {dataset.original_filename}"
        )
    
    return FileResponse(
        path=file_path,
        filename=dataset.name,
        media_type='text/csv'
    )


@router.delete("/{dataset_id}", status_code=status.HTTP_204_NO_CONTENT)
def delete_synthetic(
    dataset_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Delete a synthetic dataset from both S3 and local storage."""
    try:
        dataset_uuid = uuid.UUID(dataset_id)
    except ValueError:
        raise HTTPException(status_code=400, detail="Invalid UUID format")
    
    # Get dataset first to check if it exists and delete file
    dataset = get_synthetic_dataset_by_id(db, dataset_uuid)
    if not dataset:
        raise HTTPException(status_code=404, detail="Synthetic dataset not found")
    
    # Delete from S3 if available
    if is_s3_available() and dataset.s3_key:
        try:
            storage = get_storage_service()
            storage.delete_file(dataset.s3_key)
            logger.info(f"Deleted from S3: {dataset.s3_key}")
        except S3StorageError as e:
            logger.warning(f"S3 delete failed: {e}")
    
    # Delete local file if it exists
    if dataset.original_filename:
        upload_dir = Path(settings.upload_dir)
        file_path = upload_dir / dataset.original_filename
        if file_path.exists():
            file_path.unlink()
    
    # Delete from database
    success = delete_synthetic_dataset(db, dataset_uuid)
    if not success:
        raise HTTPException(status_code=500, detail="Failed to delete dataset")
    
    return None
